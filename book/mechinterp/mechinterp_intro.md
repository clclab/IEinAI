# Mechanistic Interpretability

Welcome to the Mechanistic Interpretability workshop! There are three papers for this course: one main paper, which everyone reads, and two papers that will be presented. For week 2, these are the following:

1. Main Paper: [Investigating Gender Bias in Language Models Using Causal Mediation Analysis](https://proceedings.neurips.cc/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf)
2. Presentation 1: [Towards Automated Circuit Discovery for Mechanistic Interpretability](https://arxiv.org/abs/2304.14997). This presentation will be on the circuits framework, and how to find circuits. Hopefully, you should also be able to skim / include results from [this paper](https://arxiv.org/abs/2310.10348) and [this paper](https://arxiv.org/abs/2403.17806) (don't bother reading Section 5 or beyond). The idea would be to first introduce circuitsâ€”what are they, and why are they useful? Then, set the three papers in dialogue, to explain how circuit-finding methods have recently evolved.
3. Presentation 2: [In-Context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html); [PDF form](https://arxiv.org/abs/2209.11895). This paper / post is very long, so you're encouraged to skim a little. The meat of their arguments ends by page 30; besides the discussion, the rest is all tables.

Note that these papers might change for week 3!

The notebook is available via [this link](https://colab.research.google.com/drive/1YSjHs1nYBEqhpg6SXyxb0tBIdZvuFxHO?usp=sharing). Please do not start work prior to the week corresponding to the mechanistic interpretability workshop that you signed up for; notebooks are subject to edits prior to this.
